{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Libraries \n",
    "import re\n",
    "from Bio import Entrez, SeqIO\n",
    "# from packages import orf_scan_analyze, query_proteins, blast_proteins\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "# import random\n",
    "# import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data & Explore Data Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DbList'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entrez.email = \"neel.mehtani@gmail.com\"\n",
    "handle = Entrez.einfo()\n",
    "\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "record.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed', 'protein', 'nuccore', 'ipg', 'nucleotide', 'structure', 'genome', 'annotinfo', 'assembly', 'bioproject', 'biosample', 'blastdbinfo', 'books', 'cdd', 'clinvar', 'gap', 'gapplus', 'grasp', 'dbvar', 'gene', 'gds', 'geoprofiles', 'homologene', 'medgen', 'mesh', 'ncbisearch', 'nlmcatalog', 'omim', 'orgtrack', 'pmc', 'popset', 'proteinclusters', 'pcassay', 'protfam', 'biosystems', 'pccompound', 'pcsubstance', 'seqannot', 'snp', 'sra', 'taxonomy', 'biocollections', 'gtr']\n"
     ]
    }
   ],
   "source": [
    "print(record[\"DbList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Count', 'RetMax', 'RetStart', 'IdList', 'TranslationSet', 'TranslationStack', 'QueryTranslation'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.esearch(db=\"nucleotide\", term=\"Brassica napus\")\n",
    "\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "record.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['937575234', '2194135529', '2193981524', '2191950016', '2191950006']\n"
     ]
    }
   ],
   "source": [
    "print(record[\"IdList\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 sequence nts:\n",
      " TCAACCACAAAGTCAAAAAACCAAATCCATCCTTTTAATTTTAAAAAAAAGTATGATTATTATTTTAGATTTTTTTCTAATCTATCTCTTTATTGCTTCT\n"
     ]
    }
   ],
   "source": [
    "## https://www.ncbi.nlm.nih.gov/Traces/wgs/?display=contigs&page=1\n",
    "Entrez.email = \"neel.mehtani@gmail.com\"\n",
    "handle = Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", id=\"QGKT01000001\")\n",
    "record = SeqIO.read(handle, \"genbank\")\n",
    "seq = record.seq\n",
    "print(\"First 100 sequence nts:\\n\", seq[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sample genome sequence: 0.373899\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of sample genome sequence: {}\".format(len(record.seq)/1000000, \"Mb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan genomic strands for potential ORFs longer than 50 codons & translate to proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Store sequence from sequence object\n",
    "seq = record.seq\n",
    "\n",
    "## Parameters\n",
    "table = 11\n",
    "min_pro_len = 50\n",
    "\n",
    "## Lists for ORF protein details\n",
    "orf_proteins, protein_wts, protein_lens = [], [], []\n",
    "\n",
    "## Start scan of both genomic strands\n",
    "for strand, nuc in [(+1, seq), (-1, seq.reverse_complement())]:\n",
    "    \n",
    "    ## Scan each possible frame\n",
    "    for frame in range(3):\n",
    "        \n",
    "        ## Transalte the frame\n",
    "        for pro in nuc[frame:].translate(table).split(\"*\"):\n",
    "            \n",
    "            if len(pro) >= min_pro_len:\n",
    "                \n",
    "                ## Run a protein \"param\" analysis -- returns molecular weight/amino acid freqs etc.\n",
    "                analysis = ProteinAnalysis(str(pro))\n",
    "                \n",
    "                ## Add protein details \n",
    "                orf_proteins.append(pro)\n",
    "                protein_wts.append(round(analysis.molecular_weight(), 3))\n",
    "                protein_lens.append(len(pro))\n",
    "                \n",
    "                ## Output to screen\n",
    "                print(\"%s...%s - length %i, strand %i, frame %i\" % (pro[:30], pro[-3:], len(pro), strand, frame))\n",
    "\n",
    "\n",
    "## ORF Protein details\n",
    "protein_wts, protein_lens = np.array(protein_wts), np.array(protein_lens)\n",
    "orf_proteins = np.array(orf_proteins, dtype='object')\n",
    "\n",
    "## Output 5 protein molar masses to screen\n",
    "for i in range(5):\n",
    "    print(\"Protein \" + str(orf_proteins[i]) + \":  \" + str(protein_wts[i]) + \"\\n\\n\")\n",
    "\n",
    "## Randomized selection for 5 proteins\n",
    "query_protein_idxs = random.sample(list(np.where(protein_lens < 1000)[0]), 5)\n",
    "\n",
    "## Determine query proteins with selected idxs\n",
    "orf_proteins_arr = np.array(orf_proteins, dtype='object')\n",
    "query_proteins = orf_proteins_arr[query_protein_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAST 5 Proteins of length <= 1000 amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_ct = 1 ## Counter for tagging results\n",
    "for q in query_proteins:\n",
    "    \n",
    "    ## Run BLAST & store returned XML file results \n",
    "    out_file = open(\"blast_{}.xml\".format(query_ct), \"w\") \n",
    "    blast_handle = NCBIWWW.qblast(\"blastp\", \"nr\", q)\n",
    "\n",
    "    out_file.write(blast_handle.read())\n",
    "    out_file.close()\n",
    "\n",
    "    blast_handle.close()\n",
    "    \n",
    "    ## Open BLAST XML results to write to custom txt file output\n",
    "    result_handle = open(\"blast_{}.xml\".format(query_ct))\n",
    "    blast_records = NCBIXML.read(result_handle)\n",
    "    \n",
    "    save_file = open(\"BLAST_query_{}_result_log\".format(query_ct), \"w\")\n",
    "    save_file.write(\"BLAST Query #{} Results -- Sequence Example\\n\".format(query_ct) + \"--------------------------\" + \"\\n\\n\")\n",
    "\n",
    "    ## Set E-Value threshold for sequences we want to write to output\n",
    "    e_value_thresh = 0.25\n",
    "    for alignment in blast_records.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            if hsp.expect < e_value_thresh:\n",
    "                save_file.write(\"sequence: {} \\n\".format(alignment.title))\n",
    "                save_file.write(\"length: {} \\n\".format(alignment.length))\n",
    "                save_file.write(\"E Value: {} \\n\".format(hsp.expect))\n",
    "                save_file.write(\"{} ...  \\n\".format(hsp.query[0:20]))\n",
    "                save_file.write(\"{} ...  \\n\".format(hsp.match[0:20]))\n",
    "                save_file.write(\"{} ...  \\n\".format(hsp.sbjct[0:20]))\n",
    "                save_file.write(\"\\n\\n\")\n",
    "            else:\n",
    "                save_file.write(\"NULL RESULT -- No hits returned!!\")\n",
    "    \n",
    "    result_handle.close()\n",
    "    query_ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def orf_scan_analyze(seq, log_dir, min_pro_len=50, table=11):\n",
    "    \n",
    "#     ## Lists for ORF protein details\n",
    "#     orf_proteins = []\n",
    "#     protein_wts = []\n",
    "#     protein_lens = []\n",
    "    \n",
    "#     ## Start scan of both genomic strands\n",
    "#     for strand, nuc in [(+1, seq), (-1, seq.reverse_complement())]:\n",
    "    \n",
    "#         ## Scan each possible frame\n",
    "#         for frame in range(3):\n",
    "\n",
    "#             ## Transalte the frame\n",
    "#             for pro in nuc[frame:].translate(table).split(\"*\"):\n",
    "\n",
    "#                 if len(pro) >= min_pro_len:\n",
    "\n",
    "#                     ## Run a protein \"param\" analysis -- returns molecular weight/amino acid freqs etc.\n",
    "#                     analysis = ProteinAnalysis(str(pro))\n",
    "\n",
    "#                     ## Add protein details \n",
    "#                     orf_proteins.append(pro)\n",
    "#                     protein_wts.append(round(analysis.molecular_weight(), 3))\n",
    "#                     protein_lens.append(len(pro))\n",
    "                    \n",
    "#                     # Output to screen\n",
    "#                     # print(\"%s...%s - length %i, strand %i, frame %i\" % (pro[:30], pro[-3:], len(pro), strand, frame))\n",
    "\n",
    "#     protein_wts = np.array(protein_wts)\n",
    "#     protein_lens = np.array(protein_lens)\n",
    "#     orf_proteins_arr = np.array(orf_proteins, dtype='object')\n",
    "\n",
    "#     save_file_path = log_dir + \"/\" + \"protein_weights\" + '.txt'\n",
    "#     save_file = open(save_file_path, \"w\")\n",
    "#     save_file.write(\"Protein Molar Mass Results\\n\" + \"--------------------------------------------\" + \"\\n\\n\")\n",
    "    \n",
    "#     for i in range(len(protein_wts)):\n",
    "#         save_file.write(\"Protein \" + str(orf_proteins[i]) + \":  \" + str(protein_wts[i]) + \"\\n\\n\")\n",
    "\n",
    "#     return orf_proteins_arr, protein_lens, query_protein_idxs\n",
    "\n",
    "# def query_proteins(orf_proteins, protein_lens):\n",
    "    \n",
    "    \n",
    "#     query_protein_idxs = random.sample(list(np.where(protein_lens < 1000)[0]), 5)\n",
    "#     query_proteins = orf_proteins[query_protein_idxs]\n",
    "\n",
    "    \n",
    "#     return query_proteins\n",
    "\n",
    "# def blast_proteins(query_proteins, log_dir, e_value_thresh=0.04):\n",
    "    \n",
    "#     Entrez.email = \"neel.mehtani@gmail.com\"\n",
    "#     query_ct = 1\n",
    "    \n",
    "#     for q in query_proteins:\n",
    "        \n",
    "#         out_file_path = log_dir + \"/\" + \"blast_{}.xml\".format(query_ct) \n",
    "#         out_file = open(out_file_path, \"w\") \n",
    "        \n",
    "#         blast_handle = NCBIWWW.qblast(\"blastp\", \"nr\", q)\n",
    "#         out_file.write(blast_handle.read())\n",
    "#         out_file.close()\n",
    "#         blast_handle.close()\n",
    "\n",
    "#         result_handle = open(out_file_path)\n",
    "#         blast_records = NCBIXML.read(result_handle)\n",
    "        \n",
    "#         save_file_path = log_dir + \"/\" + \"BLAST_query_{}_result_log\".format(query_ct) + '.txt'\n",
    "#         save_file = open(save_file_path, \"w\")\n",
    "#         save_file.write(\"BLAST Query #{} Results -- Sequence Example\\n\".format(query_ct) + \"----------------------------------------\" + \"\\n\\n\")\n",
    "        \n",
    "#         for alignment in blast_records.alignments:\n",
    "\n",
    "#             for hsp in alignment.hsps:\n",
    "#                 if hsp.expect < e_value_thresh:\n",
    "\n",
    "#     #                 content = [\"sequence: {} \\n\".format(alignment.title), \"length: {} \\n\".format(alignment.length),\n",
    "#     #                            \"E Value: {} \\n\".format(hsp.expect), \"{} ...  \\n\".format(hsp.query[0:20]), \"{} ...  \\n\".format(hsp.match[0:20]), \n",
    "#     #                            \"{} ...  \\n\".format(hsp.sbjct[0:20]), \"\\n\\n\"]\n",
    "\n",
    "#                     save_file.write(\"sequence: {} \\n\".format(alignment.title))\n",
    "#                     save_file.write(\"length: {} \\n\".format(alignment.length))\n",
    "#                     save_file.write(\"E Value: {} \\n\".format(hsp.expect))\n",
    "#                     save_file.write(\"{} ...  \\n\".format(hsp.query[0:20]))\n",
    "#                     save_file.write(\"{} ...  \\n\".format(hsp.match[0:20]))\n",
    "#                     save_file.write(\"{} ...  \\n\".format(hsp.sbjct[0:20]))\n",
    "#                     save_file.write(\"\\n\\n\")\n",
    "#                 else:\n",
    "#                     save_file.write(\"NULL RESULT -- No hits returned!!\")\n",
    "\n",
    "#         result_handle.close()\n",
    "#         query_ct += 1\n",
    "\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/Bio/Seq.py:2983: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning,\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":    \n",
    "    \n",
    "#     ## Set seed\n",
    "#     random.seed(time.time())\n",
    "\n",
    "#     ## Use Entrez for NCBI querying\n",
    "#     Entrez.email = \"neel.mehtani@gmail.com\"\n",
    "\n",
    "#     ## Handle to extract sequence data\n",
    "#     handle = Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", id=\"QGKT01000001\")\n",
    "#     record = SeqIO.read(handle, \"genbank\")\n",
    "#     handle.close()\n",
    "\n",
    "#     ## Extract sequence information from seq object\n",
    "#     seq = record.seq\n",
    "\n",
    "#     ## Parameters \n",
    "#     min_pro_len = 50 # ORF threshold\n",
    "#     table = 11 # translation reference table\n",
    "#     threshold = 0.3 # BLAST E-value threshold for output logs\n",
    "\n",
    "#     ## Output Directory\n",
    "#     log_dir = \"../data\"\n",
    "\n",
    "#     ## ORF Scanning, codon translation, and molar mass calculation\n",
    "#     orf_proteins_arr, protein_lens = orf_scan_analyze(seq, log_dir, table=table)\n",
    "\n",
    "#     ## Query Protein Indexing\n",
    "#     q_proteins = query_proteins(orf_proteins_arr, protein_lens)\n",
    "\n",
    "#     ## BLAST Analysis\n",
    "#     blast_proteins(q_proteins, log_dir, e_value_thresh=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
